import osimport torchfrom torch import nnfrom torch.utils.data import Dataset,DataLoaderfrom glob import globimport pandas as pdimport cv2import torchvisionfrom  torchvision import transformsfrom  tqdm import  tqdmimport numpy as npimport matplotlib.pyplot as pltimport json from sklearn.model_selection import train_test_splitfrom sklearn.metrics import classification_report, confusion_matrix ,cohen_kappa_scoreimport seaborn as sns#param shape_size=(160,160)test_size=.2df=pd.DataFrame(glob("./data/**/*.png"),columns=["img_path"])df["label"]=df["img_path"].apply(lambda x : x.rsplit(os.sep)[2])df=df.sample(frac=1)lbl_dict={'Normal':0, 'Deep_Caries':1, 'Restored':2, 'Mild_Caries':3}df["label"].replace(lbl_dict,inplace=True)fe_model=torchvision.models.resnet34(torchvision.models.ResNet34_Weights.IMAGENET1K_V1)def crop(img):    """    Crop ROI from image.    """    # Otsu's thresholding after Gaussian filtering    img=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)    blur = cv2.GaussianBlur(img,(5,5),0)    _, mask = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)        cnts, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)    cnt = max(cnts, key = cv2.contourArea)    x, y, w, h = cv2.boundingRect(cnt)    return img[y:y+h, x:x+w], mask[y:y+h, x:x+w]class dataset (Dataset):    def __init__(self,df,transform=None,target_transform=None):        super(dataset).__init__()        self.df=df        self.transform=transform        self.target_transform=target_transform                def __len__(self):        return(len(self.df))                    def __getitem__(self,index):        img_path,lbl=self.df.iloc[index][["img_path","label"]]        img=cv2.imread(img_path)        img,_=crop(img)        img=cv2.resize(img,shape_size)        img=cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)        if self.transform:            img=self.transform(img)        if self.target_transform:            lbl=self.target_transform(lbl)                fe=fe_model(torch.unsqueeze(img,0))        return(fe,lbl)    transform = transforms.Compose([transforms.ToTensor()])ds=dataset(df,transform)    X_fe,y=[],[]for index in tqdm(range(ds.__len__())):    fe,lbl=ds.__getitem__(index)    X_fe.append(fe)    y.append(lbl)del fe_modelX_fe=torch.vstack(X_fe).detach().numpy()y=np.array(y)         def plot_confusion_matrix(true,pred,title=None,f_name=None):    fig,ax=plt.subplots(figsize = (9,7))    sns.heatmap(confusion_matrix(true,pred),                yticklabels=['Normal', 'Deep_Caries', 'Restored', 'Mild_Caries'],                xticklabels=['Normal', 'Deep_Caries', 'Restored', 'Mild_Caries'],                 annot=True, fmt='d')    ax.set_xlabel('Predicted')    ax.set_ylabel('Truth')    ax.set_title(title)    if f_name:        plt.savefig(f_name,dpi=600)    plt.show()                def classifier(clf,data,clf_name):    X_train,y_train,X_test,y_test=data    clf.fit(X_train,y_train)    y_pred=clf.predict(X_test)        classfi_report=classification_report(y_test, y_pred,output_dict=True)    Con_matrix=confusion_matrix(y_test, y_pred)        kappa=cohen_kappa_score(y_test, y_pred)    accuracy=classfi_report['accuracy']    precision= classfi_report['macro avg']['precision']    recall= classfi_report['macro avg']['recall']    f1_score= classfi_report['macro avg']['f1-score']    clf_metrics={"kappa":kappa,"accuracy":accuracy,"precision":precision,"recall":recall,"f1_score":f1_score}        plot_confusion_matrix(y_test, y_pred, title=f"{clf_name} confusion matrix" ,f_name=f"./result/{clf_name}/confusion_matrix.jpg")        return (y_pred,y_test,clf_metrics,Con_matrix)#import classifiersfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.ensemble import RandomForestClassifier ,ExtraTreesClassifierfrom sklearn.ensemble import BaggingClassifier ,AdaBoostClassifier ,GradientBoostingClassifierfrom sklearn.tree import DecisionTreeClassifierfrom sklearn.svm import SVC ,LinearSVCfrom xgboost import XGBClassifierfrom sklearn.ensemble import StackingClassifierfrom sklearn.ensemble import VotingClassifierfrom sklearn.linear_model import LogisticRegressionfrom collections import OrderedDictestimators = [ ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),               ('svr', LinearSVC(random_state=42))]classifier1 = ExtraTreesClassifier(random_state=0)classifier2 = RandomForestClassifier(max_depth=100, n_estimators=10,random_state=125)classifier3 = XGBClassifier(n_estimators=10)clf_dict=OrderedDict(                    {                           "Bagging_KNN":BaggingClassifier(KNeighborsClassifier(),max_samples=0.5, max_features=0.5),                        "Bagging_SVM":BaggingClassifier(SVC(), n_estimators=10, random_state=0),                        "RandomForest":RandomForestClassifier(max_depth=100, n_estimators=10,random_state=125),                        "ExtraTrees":ExtraTreesClassifier(n_estimators=10,min_samples_split=2, random_state=0),                        "AdaBoost":AdaBoostClassifier(n_estimators=100),                        "GradientBoosting":GradientBoostingClassifier(),                        "DecisionTree":DecisionTreeClassifier(),                        "svm":SVC(kernel="rbf",probability=True),                        "XGBoost":XGBClassifier(n_estimators=10),                        "Stacking_rf_svr":StackingClassifier(estimators=estimators, final_estimator=LogisticRegression()),                        "voting":VotingClassifier(estimators=[ ('ET', classifier1), ('RF', classifier2), ('XGB', classifier3)],voting="soft"),                     })metrics_dict=OrderedDict()CM_dict=OrderedDict()res_dict=OrderedDict()X_train,X_test,y_train,y_test=train_test_split(X_fe,y,test_size=test_size)data=(X_train,y_train,X_test,y_test)for clf_name in clf_dict.keys():    os.makedirs(f"./result/{clf_name}",exist_ok=True)    clf=clf_dict[clf_name]    y_pred,y_test,metrics,CM=classifier(clf,data,clf_name)        metrics_dict[clf_name]=metrics    CM_dict[clf_name]=CM    res_df=pd.DataFrame(zip(y_pred,y_test),columns=["pred","real"])    res_df.to_csv(f"./result/{clf_name}/res.csv")    with open(f"./result/{clf_name}/metrics.json", "w") as metric_file:        json.dump(metrics,metric_file)         metric_file.close()    